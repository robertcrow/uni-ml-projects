\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Machine Learning basics}{3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Linear regression}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Minimizing the cost function - gradient descent}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Improving linear regression models}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Regularization and feature selection}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Ridge regression (L2)}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Lasso regression (L1)}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Elastic net regression}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature selection}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Logistic regression}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Classification problem error metrics}{5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Confusion matrix}}{5}\protected@file@percent }
\newlabel{fig:my_label}{{1.1}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces ROC}}{5}\protected@file@percent }
\newlabel{fig:my_label}{{1.2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces AUC}}{6}\protected@file@percent }
\newlabel{fig:my_label}{{1.3}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces PR Curve}}{6}\protected@file@percent }
\newlabel{fig:my_label}{{1.4}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Multiple class error metrics}{6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Confusion matrix for 3 class problem}}{7}\protected@file@percent }
\newlabel{fig:my_label}{{1.5}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Naive Bayes}{7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Bayes theorem}}{7}\protected@file@percent }
\newlabel{fig:my_label}{{1.6}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Potential problems}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Support Vector Machines}{8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces SVM - decision boundary}}{8}\protected@file@percent }
\newlabel{}{{1.7}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Comparison of cost functions - logistic regression and SVM}}{8}\protected@file@percent }
\newlabel{fig:my_label}{{1.8}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces SVM - outlier sensitivity}}{9}\protected@file@percent }
\newlabel{fig:my_label}{{1.9}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Decision trees}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Pros and cons}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Bagging - bootstrap aggregation}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}Strengths}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Random forest}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Boosting and stacking}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}Boosting}{10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Boosting - creating consecutive classifiers}}{11}\protected@file@percent }
\newlabel{fig:my_label}{{1.10}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Boosting - combining classifiers}}{11}\protected@file@percent }
\newlabel{fig:my_label}{{1.11}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Boosting - Loss function}}{12}\protected@file@percent }
\newlabel{fig:my_label}{{1.12}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Boosting - other loss functions}}{12}\protected@file@percent }
\newlabel{fig:my_label}{{1.13}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces Boosting - overfitting}}{13}\protected@file@percent }
\newlabel{fig:my_label}{{1.14}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.15}{\ignorespaces Boosting - tuning the model}}{13}\protected@file@percent }
\newlabel{fig:my_label}{{1.15}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.2}Stacking}{13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.16}{\ignorespaces Stacking}}{14}\protected@file@percent }
\newlabel{fig:my_label}{{1.16}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Clustering}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.1}K-means algorithm}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.2}Distance metrics}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.3}Hierarchical Agglomerative Clustering algorithm}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.10}Dimensionality reduction}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10.1}Single Value Decomposition}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10.2}Multi-dimensional scaling}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Deep Learning basics}{17}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Neural Networks}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Training neural nets}{17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Chain rule - each term can be interpreted as an estimate of the change of activations with respect to the input, backpropagation is employed by multiplication of terms from the following layers.}}{17}\protected@file@percent }
\newlabel{fig:my_label}{{2.1}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Other activation functions}{18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Updating weights }{18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Classification problems with neural nets}{19}\protected@file@percent }
